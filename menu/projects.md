---
layout: page
title: Projects
---


Here's a small selection of projects that I have done. (Still under construction)

[<span style="font-size:larger;">Conditional Wasserstein GAN-based Oversampling of Tabular Data for Imbalanced Learning</span>](https://github.com/justinengelmann/GANbasedOversampling)  
*MSc Thesis*  
Developed a novel GAN-based oversampling method that can effectively model tabular data with both categorical and numerical columns. Previous methods did not incorporate recent advancements from the literature on generating realistic tabular data with GANs and did not allow for categorical variables, which are commonplace in real-world tabular data. Empirical results evidence the competitiveness of GAN-based oversampling. [\[preprint\]](https://arxiv.org/abs/2008.09202)

[<span style="font-size:larger;">Controllability of Risk in Financial Networks</span>](https://github.com/justinengelmann/Network-Games-and-Mechanism-Design-SS19)  
*MSc Seminar Network Games and Mechanism Design (Thematic Einstein Semester of the MATH+ Excellence Cluster)*  
Applied the concept of controllability to a graph of risk interdependence of major financial institutions and computed the minimum input set.

[<span style="font-size:larger;">Profit-Efficient A/B Testing through Inverse Propensity Score Weighting</span>](https://github.com/justinengelmann/Network-Games-and-Mechanism-Design-SS19)  
*MSc Seminar Causal Machine Learning*  
Implemented a novel approach for maximising outcome metrics during an A/B test/Randomised Controlled Trial by leveraging pre-existing domain knowledge and tested it with a simulation study.

[<span style="font-size:larger;">Few-shot Object Recognition with Convolutional Neural Networks</span>](https://github.com/justinengelmann/TX2020-Philips-Challenge-Inference)  
*Eindhoven Tech Experience 2020 - Challenge by Philips*  
I was one of [21 winners out of over 900 participants](https://brainporteindhoven.com/int/brainport-for-you/work/tech-xperience-winners-2020/). I finetuned a pre-trained VGG16 CNN to recognise one of four products with a small dataset of 20 labelled images per class and wrote a script for inference on new images.

[<span style="font-size:larger;">Reducing Ecommerce Returns Costs through Profit-Sensitive Prescriptive Modelling</span>](https://github.com/justinengelmann/Business-Analytics-and-Data-Science-WS1819)  
*MSc Course Business Analytics and Data Science*  
Ranked 2nd out of 118 students in In-Class Kaggle competition for predicting Ecommerce returns which was scored on plain ROC-AUC rather than profit. Implemented an algorithm to create a selective averaging ensemble of heterogeneous base models from scratch which maximises profit rather than AUC. Final ensemble increased profits by 30% compared to the optimal na√Øve baseline strategy of never intervening. 
